{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, abspath, expanduser\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from rio_geom import rio_to_exterior\n",
    "from datetime import timedelta\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxa\n",
    "import contextily as ctx\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from uavsar_pytools.snow_depth_inversion import depth_from_phase\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = expanduser('~/scratch/data/uavsar/snowpits')\n",
    "pits_dir = join(data_dir, 'pits')\n",
    "swe = pd.read_csv(join(data_dir, 'SNEX20_TS_SP_Summary_SWE_v01.csv'), parse_dates = ['Date/Local Standard Time'], index_col= 'PitID')\n",
    "\n",
    "env = pd.read_csv(join(data_dir, 'SNEX20_TS_SP_Summary_Environment_v01.csv'), parse_dates = ['Date/Local Standard Time'], index_col= 'PitID')\n",
    "\n",
    "pit_sum = pd.concat([swe, env], axis = 1).reindex(swe.index)\n",
    "pit_sum = pit_sum.loc[:,~pit_sum.columns.duplicated()]\n",
    "pit_sum = pit_sum.rename(columns = {'Date/Local Standard Time':'date'})\n",
    "pit_sum = gpd.GeoDataFrame(pit_sum, geometry=gpd.points_from_xy(pit_sum['Longitude (deg)'], pit_sum['Latitude (deg)']), crs = 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(expanduser('~/scratch/data/uavsar/image_fps'), 'rb') as f:\n",
    "    image_fps = pickle.load(f)\n",
    "\n",
    "res = []\n",
    "for i, image_fp in enumerate(image_fps):\n",
    "    if i == i:\n",
    "        dic = {}\n",
    "        dic['image_data'] = image_fp\n",
    "        loc = image_fp['location']\n",
    "        dic['loc'] = loc\n",
    "        if image_fp['flight1'].date().year == 2021 or image_fp['pol'] != 'HH':\n",
    "            pass\n",
    "        else:\n",
    "            geom = rio_to_exterior(image_fp['cor'])\n",
    "            for i, dt in enumerate(['flight1', 'flight2']):\n",
    "                dic[f't{i+1}'] = image_fp[dt]\n",
    "                dt = image_fp[dt].date()\n",
    "                # Form a date range to query on either side of our chosen day \n",
    "                date_range = [dt + i * timedelta(days=1) for i in [-2, 0, 2]]\n",
    "                df_range = pit_sum[(pit_sum.date.dt.date > date_range[0]) & (pit_sum.date.dt.date < date_range[-1])]\n",
    "\n",
    "                if len(df_range) > 0:\n",
    "                    # View snow pits that are +/- 1 day of the first UAVSAR flight date\n",
    "                    geom = geom.to_crs(df_range.crs)\n",
    "                    points_within = gpd.sjoin(df_range, geom, predicate='within')\n",
    "                    points_within = points_within.drop(['index_right'], axis=1)\n",
    "                    dic[f't{i+1}_pit_num'] = len(points_within)\n",
    "                    dic[f't{i+1}_pits'] = points_within\n",
    "                else:\n",
    "                    dic[f't{i+1}_pit_num'] = len(points_within)\n",
    "                    print(f'{dt}_{loc} has none')\n",
    "            res.append(pd.DataFrame.from_dict([dic]))\n",
    "res = pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/bsuhome/zacharykeskinen/uavsar/results/snow_pits'\n",
    "with open(join(res_dir, 'uavsar_pits.pkl'), 'rb') as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick = res.drop(['image_data','t1_pits','t2_pits'], axis = 1)\n",
    "quick.loc[np.isnan(quick.merged_pits_num), 'merged_pits_num']= 0\n",
    "quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_cols = ['index_t2','Location_t1', 'Site_t1', 'date_t1', 'date_t2','UTM Zone_t1', 'Latitude (deg)_t1', 'Longitude (deg)_t1', 'Density Mean (kg/m^3)_t1', 'Density Mean (kg/m^3)_t2', 'SWE (mm)_t1', 'Snow Depth (cm)_t1', 'SWE (mm)_t2', 'Snow Depth (cm)_t2', 'Ground Condition_t1', 'Ground Condition_t2', 'Height of Ground Vegetation (cm)_t1', 'Ground Roughness_t1', 'Canopy_t2', 'sd_diff', 'swe_diff']\n",
    "\n",
    "site_res = pd.DataFrame()\n",
    "for i, r in res.iterrows():\n",
    "    if not r.t1_pits.empty and not r.t2_pits.empty:\n",
    "        epsg = 26900 + int(r.t1_pits.iloc[0]['UTM Zone'].replace('N',''))\n",
    "        merged = gpd.sjoin_nearest(r.t1_pits.to_crs(epsg), r.t2_pits.to_crs(epsg), max_distance = 50, lsuffix='t1', rsuffix='t2')\n",
    "        merged['sd_diff'] = merged['Snow Depth (cm)_t2'] - merged['Snow Depth (cm)_t1']\n",
    "        merged['swe_diff'] = merged['SWE (mm)_t2'] - merged['SWE (mm)_t1']\n",
    "        res.loc[i, 'merged_pits_num'] = len(merged)\n",
    "        for label in ['fp','inc','cor','hgt']:\n",
    "                img = rxa.open_rasterio(r.image_data[label])\n",
    "                img = img.rio.reproject(dst_crs = epsg)\n",
    "                for i_site, r_site in merged.iterrows():\n",
    "                    site_name = r_site.Location_t1 + '-' + r_site.Site_t1 + '-' + str(r_site.date_t1.date()) + '-' + str(r_site.date_t2.date())\n",
    "                    if label == 'fp':\n",
    "                        label = 'unw'\n",
    "                    site_res.loc[site_name, label] = img.sel(x = r_site.geometry.x, y = r_site.geometry.y, method = 'nearest', tolerance = 50).values[0]\n",
    "                    site_res.loc[site_name, 'index_t1'] = i_site\n",
    "                    for col in site_cols:\n",
    "                        site_res.loc[site_name, col] = r_site[col]\n",
    "                    # site_res.loc[site_name, f'swe_diff'] = r_site.swe_diff\n",
    "site_res = site_res.apply(pd.to_numeric, errors='ignore')\n",
    "num_cols = site_res.columns[site_res.dtypes == float]\n",
    "num_cols = num_cols.drop(['Latitude (deg)_t1', 'Longitude (deg)_t1'])\n",
    "cat_cols = ['Ground Condition_t1', 'Ground Condition_t2', 'Height of Ground Vegetation (cm)_t1', 'Ground Roughness_t1', 'Canopy_t2']\n",
    "site_res[cat_cols] = site_res[cat_cols].apply(lambda x: x.astype('category', errors = 'ignore'))\n",
    "\n",
    "res_dir = '/bsuhome/zacharykeskinen/uavsar/results/snow_pits'\n",
    "with open(join(res_dir, 'overlapping_pits.pkl'), 'wb') as f:\n",
    "    pickle.dump(site_res, f)\n",
    "\n",
    "res_dir = '/bsuhome/zacharykeskinen/uavsar/results/snow_pits'\n",
    "with open(join(res_dir, 'uavsar_pits.pkl'), 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = '/bsuhome/zacharykeskinen/uavsar/results/snow_pits'\n",
    "with open(join(res_dir, 'overlapping_pits.pkl'), 'rb') as f:\n",
    "    site_res = pickle.load(f)\n",
    "num_cols = site_res.columns[site_res.dtypes == float]\n",
    "num_cols = num_cols.drop(['Latitude (deg)_t1', 'Longitude (deg)_t1'])\n",
    "cat_cols = ['Ground Condition_t1', 'Ground Condition_t2', 'Height of Ground Vegetation (cm)_t1', 'Ground Roughness_t1', 'Canopy_t2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in site_res.columns:\n",
    "    if col in num_cols:\n",
    "        sns.scatterplot(x = col, y = 'cor', data = site_res)\n",
    "        plt.show()\n",
    "    if col in cat_cols:\n",
    "        sns.violinplot(x = col, y = 'cor', data = site_res)\n",
    "        plt.show()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_col in cat_cols:\n",
    "    for num_col in num_cols:\n",
    "        sns.violinplot(x = cat_col, y = num_col, data = site_res)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be18628f3b6aaaf0d9a50c1a0a68c0122e22b01f7b4495836f3dc0caac12767e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
